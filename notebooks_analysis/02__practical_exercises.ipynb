{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172a7cc648754fe6a542b982a433239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5295d0fdba624176b2ab1930801859d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c9ec5d6d524191a725fc6969fd4887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26773d3b31c941d9a24083c5c81fa2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6845788a5cfd4ff8b2a97cc78a519c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f00d7249e36409aaf4f2ffa5fddb655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713e3194397e4fd99c570a7adf253a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the IMDb dataset\n",
    "dataset = load_dataset('imdb')\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "# Split the training data into features and labels\n",
    "X_train_orig = train_df['text']\n",
    "y_train_orig = train_df['label']\n",
    "\n",
    "# Split the test data into features and labels\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Create an artificial imbalance by removing randomly selected positive reviews (label = 1) from the training data\n",
    "positive_indices = np.where(y_train_orig == 1)[0]\n",
    "negative_indices = np.where(y_train_orig == 0)[0]\n",
    "\n",
    "# Randomly choose 80% of the positive indices to remove\n",
    "np.random.seed(42)  # for reproducibility\n",
    "drop_indices = np.random.choice(positive_indices, size=int(0.80*len(positive_indices)), replace=False)\n",
    "\n",
    "# Create the unbalanced training data by dropping the selected positive reviews\n",
    "X_train_unbal = X_train_orig.drop(drop_indices)\n",
    "y_train_unbal = y_train_orig.drop(drop_indices)\n",
    "\n",
    "# Shuffle the training data\n",
    "X_train_orig, y_train_orig = shuffle(X_train_orig, y_train_orig, random_state=42)\n",
    "X_train_unbal, y_train_unbal = shuffle(X_train_unbal, y_train_unbal, random_state=42)\n",
    "\n",
    "# Now you have original and unbalanced training sets, and a common test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1     2500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_unbal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_orig.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Exercises:\n",
    "\n",
    "1. **Dataset Exploration**:\n",
    "    - Explore the original training set and the unbalanced training set. What are the proportions of positive and negative reviews in both?\n",
    "\n",
    "2. **Text Encoding**:\n",
    "    - Encode the text data from both training sets using the TF-IDF vectorization method. \n",
    "\n",
    "3. **Model Training and Evaluation (Unbalanced Data)**:\n",
    "    - Train a Logistic Regression classifier on the unbalanced training data.\n",
    "    - Evaluate the model on the common test set using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
    "\n",
    "4. **Data Balancing**:\n",
    "    - Balance the unbalanced training data using oversampling technique. Make sure the oversampling is done only on the training data.\n",
    "    \n",
    "5. **Model Training and Evaluation (Balanced Data)**:\n",
    "    - Train a Logistic Regression classifier on the balanced training data.\n",
    "    - Evaluate the model on the common test set using the same metrics as above.\n",
    "    - Compare the performance of the model trained on unbalanced data versus the model trained on balanced data.\n",
    "     - Repeat the training now using the original training data.\n",
    "\n",
    "6. **Data Visualization**:\n",
    "    - Use t-SNE to visualize the text encoding of both the original and balanced training data in 2D space. Color the points based on the labels.\n",
    "\n",
    "7. **TF-IDF with PCA**\n",
    "     - Use PCA to reduce the dimensionality of the TF-IDF on the balanced data. Standardize the feature matrix and get those components that explain at least 95% of the variance. Compare the results without using PCA. \n",
    "\n",
    "8. **(Optional)**\n",
    "    - Explore other machine learning models and compare their performance with Logistic Regression on this task.\n",
    "    - Consider tuning the hyperparameters of your models for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1\n",
    "\n",
    "lab0_count, lab1_count = y_train_unbal.value_counts()\n",
    "lab0_count/(lab0_count+lab1_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m      3\u001b[0m vectorizer_tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m----> 4\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m vectorizer_tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a261fe3232d26f5c8a3b17afd155c889a6f52aad30d4dff29769029555a05e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('phd-corpora')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
