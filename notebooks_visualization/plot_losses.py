import matplotlib.pyplot as plt

epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
 13, 14, 15, 16, 17, 18, 
 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
 29, 30, 31, 32, 33, 34, 35, 36, 37, 38,
 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,
 52,
 53,
 54,
 55,
 56,
 57,
 58,
 59,
 60,
 61,
 62,
 63,
 64,
 65,
 66,
 67,
 68,
 69,
 70,
 71,
 72,
 73,74,75,76,77]

train_loss = [0.04365885280131888,
 0.03151224122068736,
 0.02666934732047505,
 0.024368892234584123,
 0.022782175587099066,
 0.021417076167704434,
 0.020535929935110074,
 0.01997701389340855,
 0.01938245883031783,
 0.018244597312405485,
 0.018680081169980406,
 0.01828423457877725,
 0.018388288763693188,
 0.01799639845827212,
 0.017843517173550996,
 0.017590272445421957,
 0.017435623587623964,
 0.01727112378210472,
 0.017223250298474352,
 0.017043080246424838,
 0.01633076213097261,
 0.016230025828713458,
 0.016224423699317737,
 0.016072570074616037,
 0.016071841599595196,
 0.0159753048824195,
 0.01593959142288001,
 0.015946097379163433,
 0.015943525701541363,
 0.01548508969299436,
 0.015488552669576971,
 0.015355321222432085,
 0.015423252159532976,
 0.015350165817078952,
 0.015373845040273856,
 0.015314216124027055,
 0.01527131521158876,
 0.01533125476038483,
 0.015215053952486169,
 0.015099611669296777,
 0.015056351354085628,
 0.015096432699586151,
 0.015034127096718475,
 0.015039076930320019,
 0.01502234323709256,
 0.015106887928718674,
 0.015016649638288882,
 0.014977096081008367,
 0.014937199606738824,
 0.014889418063991862,
 0.016004791745448763,
 0.01625698980760087,
 0.016107013654154085,
 0.01609485261522817,
 0.015981509195900735,
 0.015965868803491726,
 0.01585403236557352,
 0.01591486887632109,
 0.015821019575532596,
 0.015255448580735388,
 0.015164342364264604,
 0.015179815547800835,
 0.015091350294700342,
 0.015148612549031633,
 0.015046492329968835,
 0.015040563833852225,
 0.015087171927069088,
 0.015068073304545527,
 0.014691970884064202,
 0.014697564643185066,
 0.014602937069631665,
 0.014649052678202528,
 0.014612059280166357,
 0.014624598644310175,
 0.014595574921337416,
 0.01456839647292076,
 0.014631603974489565]

val_loss = [0.03593466945265958,
 0.028545409047959047,
 0.025579039537168426,
 0.025165707009647965,
 0.02198169166820312,
 0.02117403912776654,
 0.01978920497547049,
 0.020687457789248284,
 0.01894653522742724,
 0.017745918568668015,
 0.021027227726961494,
 0.020036690629198464,
 0.018358159417269426,
 0.019412323567640343,
 0.018362043510883226,
 0.018266134092225394,
 0.01752946644577138,
 0.0177445608712391,
 0.017434562377016478,
 0.01685292197716072,
 0.016007239776535318,
 0.016052195358030295,
 0.016291075044337217,
 0.015809175114087557,
 0.01594119375451989,
 0.01627335187321136,
 0.015882534581586855,
 0.01613784404556959,
 0.01616270417227931,
 0.01560231570769614,
 0.015536202391216515,
 0.015547764197060275,
 0.015848172290267748,
 0.01552074466652553,
 0.015439270030057758,
 0.015440135673030254,
 0.01563499894403263,
 0.01552787095034888,
 0.015344850197776195,
 0.015405307882764471,
 0.015396934062447569,
 0.01517486915744226,
 0.015213123172384883,
 0.015171505357010649,
 0.015520290599777064,
 0.015240825319645601,
 0.015272322691840316,
 0.01505803368951476,
 0.015082508727156241,
 0.015027358564078261,
 0.01597451916767643,
 0.016657778181545776,
 0.016261479595180497,
 0.016445840358597422,
 0.01629530394945396,
 0.016592141480074016,
 0.01597012719566669,
 0.01595125013295937,
 0.016264841550055448,
 0.015281783228893892,
 0.015429372745437906,
 0.015592013964207348,
 0.015139384836026835,
 0.015414556983960877,
 0.015570562896788667,
 0.015397435771899486,
 0.01564099281650344,
 0.015787932355332813,
 0.015282076014496318,
 0.014913024620041935,
 0.014970532396312701,
 0.015332377618264168,
 0.01498303510282838,
 0.015018539050371822,
 0.015100392854746875,
 0.01506540429598968,
 0.015028353977025649]


plt.figure(figsize=(10, 6))
plt.plot(epochs, train_loss, label='Training Loss', marker='o')
plt.plot(epochs, val_loss, label='Validation Loss', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Over Epochs')
plt.legend()
plt.grid(True)
plt.show()